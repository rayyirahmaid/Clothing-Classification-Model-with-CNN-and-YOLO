{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayyirahmaid/Clothing-Classification-Model-with-CNN-and-Transformer/blob/main/Tubes_18321013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fLYCK22l1XA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchvision.models import alexnet\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dsphV6qLOke"
      },
      "outputs": [],
      "source": [
        "# Mount Drive ke memori google collab\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ke dataset utama\n",
        "dataset_path = '/content/drive/My Drive/processed_dataset'  # Ganti dengan path dataset utama Anda\n",
        "\n",
        "# Path ke folder train dan test di /content\n",
        "train_dir = \"/content/train\"  # Path untuk training\n",
        "test_dir = \"/content/test\"  # Path untuk testing\n",
        "\n",
        "# Membuat folder Train dan Test\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Step 4: Loop untuk setiap kelas dalam folder Dataset\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    if os.path.isdir(class_path):  # Pastikan hanya memproses folder kelas\n",
        "        print(f\"Memproses kelas: {class_name}\")\n",
        "\n",
        "        # Buat folder untuk kelas ini di Train dan Test\n",
        "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "        # Ambil semua file dari kelas\n",
        "        all_files = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
        "\n",
        "        # Bagi file ke training (70%) dan testing (30%) secara acak\n",
        "        train_files, test_files = train_test_split(all_files, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Pindahkan file ke folder Train dan Test\n",
        "        for file in train_files:\n",
        "            shutil.copy(file, os.path.join(train_dir, class_name))\n",
        "        for file in test_files:\n",
        "            shutil.copy(file, os.path.join(test_dir, class_name))\n",
        "\n",
        "print(\"Dataset telah berhasil dibagi menjadi Train dan Test!\")\n",
        "print(f\"Folder Train: {train_dir}\")\n",
        "print(f\"Folder Test: {test_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yqi6P1rLYlc"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "batch_size = 32\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNtmG76mLd9q"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "num_classes = len(train_dataset.classes)\n",
        "model = alexnet(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hno_mUo5QaaM"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "\n",
        "    # Validation Loop\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(outputs.argmax(1).cpu().numpy())\n",
        "    val_loss = running_loss / len(test_loader)\n",
        "    val_acc = correct / total\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan model ke file\n",
        "model_path = \"/content/drive/My Drive/saved_model.pth\"  # Ganti dengan path penyimpanan Anda\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model telah disimpan ke {model_path}\")"
      ],
      "metadata": {
        "id": "GdQ3QiJ2WWO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njYy9rLJocCx"
      },
      "outputs": [],
      "source": [
        "# Evaluation and Metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=train_dataset.classes))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes)\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dataset\n",
        "train_dir = '/content/train'  # Make sure this points to your training data\n",
        "model_save_path = '/content/vit_clothing_model.pth'\n",
        "batch_size = 32\n",
        "num_epochs = 20  # Start with 5-10 epochs to see how it performs\n",
        "learning_rate = 0.001\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Training on device: {device}\")"
      ],
      "metadata": {
        "id": "NVbtcNnNxiC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "print(f\"Loading training data from: {train_dir}\")\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(f\"Training on {num_classes} classes: {class_names}\")"
      ],
      "metadata": {
        "id": "CR_vYLp-yQzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Initialization\n",
        "print(\"Downloading Pre-trained Vision Transformer...\")\n",
        "# pretrained=True downloads the weights. num_classes replaces the output layer.\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define how we measure error (CrossEntropy) and how we update weights (Adam optimizer)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "fpqRwq7VyWBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Training Loop\n",
        "print(\"Starting training process...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: predict the clothing\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass: calculate the errors and update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track accuracy and loss\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc*100:.2f}%\")\n",
        "\n",
        "# Save the Fine-Tuned Model\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Training complete! Model saved successfully to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtYneHNG08XT",
        "outputId": "b17ff0cc-8b14-4db4-c60b-3fda7d2a9fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training process...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Dataset\n",
        "test_dir = '/content/test'\n",
        "model_weights_path = '/content/vit_clothing_model.pth' # Pointing to the file we just saved!\n",
        "batch_size = 32\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Evaluating on device: {device}\")\n",
        "\n",
        "# Data Preparation (No Augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "class_names = test_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# 3. Model Initialization\n",
        "print(\"Initializing Vision Transformer...\")\n",
        "# pretrained=False because we are about to load our own custom weights\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=num_classes)\n",
        "\n",
        "# Load the weights we just trained\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path, map_location=device))\n",
        "    print(\"Custom weights loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Error: Could not find weights at {model_weights_path}. Did you run the training script first?\")\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval() # Set to evaluation mode\n",
        "\n",
        "# Evaluation Loop\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "print(\"Running predictions on test data...\")\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "# Metrics and Visualization\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Classification Report:\")\n",
        "print(\"=\"*50)\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d', ax=ax)\n",
        "plt.title('Vision Transformer Confusion Matrix')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqJJ72fpzj6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woZohYRJzsXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy0hUSm0hj+pXSNcebSDFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}